This serves as a living document of the aims of ImageWolf.

## Introduction & Resources

This is a link to a talk by a google engineer talking about
distribution of large files over a large network.

[https://www.usenix.org/sites/default/files/conference/protected-files/lisa_2014_talk.pdf]()

The presentation talks about splitting package distribution into two
parts, metadata and data. The metadata is distributed quickly through
a central medium (BigTable database), whereas the docker images are
distributed through a slower medium (Colossus File-System).

This is similar to the ImageWolf issue. We now have access to many
hundreds of nodes (potentially) and wish to distribute updates quickly
and efficiently to all/some specified subset of nodes.

ImageWolf is a push-based system, although implementing pull would not
be too challenging. Currently only one ImageWolf instance is notified
when a new image needs to be distributed between all instances.

When this happens ImageWolf downloads the image from the registry and
then distributes it to all nodes using BitTorrent.
Currently there is zero filtering on which nodes should be sent the
image.

There is already logic within Kubernetes to help with cache-locality
[#20140](https://github.com/kubernetes/kubernetes/pull/20140).

With a method to 'prefetch' images one would be able to exploit this,
rolling out to machines which managed to get a hold of the newly
deployed image first. This is not currently supported, but ImageWolf
could be used to solve the problem:
[#16466](https://github.com/kubernetes/kubernetes/issues/16466)

One of the solutions discussed was p2p sharing, which is actually the
solution used in MTM (see slides above) within google for package
distribution.

An interesting discussion on the limitations of Docker
configurability:

[#1319](https://github.com/kubernetes/kubernetes/issues/1319)


Something like this:
[squid-in-a-can](https://github.com/jpetazzo/squid-in-a-can.git)

might do a decent job...

## What is needed for a private Image registry

__Out of band Image pulls:__ As seen
in [#43915](https://github.com/kubernetes/kubernetes/issues/43915)
if image pulls become slow, then issues start occurring with the
Docker daemon stability. This should not be the case, and can be
fixed by not having the image pull be a central process in the image
deployment lifecycle. As this is currently not possible to resolve
directly, one solution is to point the docker daemon at a closer
caching registry which fails if the image is not available. This
reduces the mean time to error and reducing the load on the Docker
daemon.

__Pre-warming of local registry's:__ A cold pull from the Docker hub
can be a slow process, especially when deploying over many hundreds of
machines. One solution to this problem is to optimistically move new
data into the cache that we think may be used in the near future.

__Only audited/signed images:__ When pulling from the Docker hub, the
quality of images is pretty variable. There is currently no way to
verify that a pulled image was created by the owning party. In a way,
we have moved back to pulling and executing random binaries from
public ftp servers. This is a feature offered by the 'Enterprise
facing' tools that currently exist.

__Fine-grained access control:__ Have fine-grained access control from
nodes, perhaps enforcing specific requirements before nodes may access
images. Useful for financial institutions which must conform to higher
security standards.

__Immutable Images:__ Once an image has been pushed, it may not be
'patched', If an image is tagged in a registry, then the tag cannot be
moved... (Is this desired functionality?, for sure!). It should not be
possible to overwrite tags, perhaps with a `-f` command-line switch!

__Disable access to DockerHub:__ This is an important requirement for
projects with strict requirements on ingress/egress from nodes. Having
a method to restrict which registries are considered 'acceptable', or
even disabling `docker pull` altogether would be reasonable. It is
currently possible to specify a pull policy for a container, but not
over a namespace, or even a cluster. This might be necessary in order
to enforce no fallback to the docker registry.

Original discussion
[#1319](https://github.com/kubernetes/kubernetes/issues/1319)

Follow up discussion around the addon for k8s. This one is pretty
interesting as it explicitly is discussing what would be wanted in a
registry.
[#19033](https://github.com/kubernetes/kubernetes/issues/19033)

## Alternatives

### GCE cache of Dockerhub.

This can only be done when setting-up/reconfiguring the entire
cluster.
[#2592](https://github.com/kubernetes/kubernetes/pull/2592)
shows how one can use the GCE cache to pull images much faster than
falling back to the Dockerhub. This is pretty intrusive though, and
doesn't allow for an easy win. This is however very robust as you
don't need to maintain anything else. If you are setting up on Google
Infra, it's probably worth it.

### Squid-in-a-can

Pretty basic, couldn't get it working.


### People who may be interested in ImageWolf

- https://twitter.com/cognitiaclaeves
- https://www.clarifai.com/


## Potential Solutions

# Registry per node

Explains itself, there are different ways that this can be done...
Each different alternative needs to be described in more detail
Distribution methods (P2P, Block Storage, others?)

# One Registry on Master node

Discuss...

# No pulling, only _docker load_

Discuss...
